"""
ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ë™ì‘ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í”„ë¡ íŠ¸ì—”ë“œ/ë°±ì—”ë“œ ì—°ë™ ì—†ì´ë„
ë©”íƒ€ë°ì´í„° ì‹œìŠ¤í…œì´ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
"""

import os
import sys
from pathlib import Path
from datetime import datetime
import json

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

# í™˜ê²½ ë³€ìˆ˜ ì–µì œ
os.environ["ORT_LOGGING_LEVEL"] = "3"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

from rag.pipeline import RAGPipeline
from rag.chunker import DocumentChunker
import config


def test_1_structure_extraction():
    """í…ŒìŠ¤íŠ¸ 1: extract.pyì—ì„œ êµ¬ì¡° ì •ë³´ ì¶”ì¶œ í™•ì¸"""
    print("\n" + "="*70)
    print("í…ŒìŠ¤íŠ¸ 1: ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ (extract.py)")
    print("="*70)
    
    extracted_dir = Path(config.EXTRACTED_DIR)
    
    if not extracted_dir.exists():
        print("âŒ extracted_results í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € python auto_add.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return False
    
    # ì¶”ì¶œëœ í´ë” ëª©ë¡
    extracted_folders = [d for d in extracted_dir.iterdir() if d.is_dir() and d.name.startswith('extracted_')]
    
    if not extracted_folders:
        print("âŒ extracted_resultsì— ì¶”ì¶œëœ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    print(f"\nâœ“ ë°œê²¬ëœ ì¶”ì¶œ í´ë”: {len(extracted_folders)}ê°œ")
    
    # ì²« ë²ˆì§¸ í´ë” ë¶„ì„
    test_folder = extracted_folders[0]
    print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ í´ë”: {test_folder.name}")
    
    # êµ¬ì¡° JSON íŒŒì¼ ì°¾ê¸°
    structure_files = list(test_folder.glob("*êµ¬ì¡°.json"))
    
    if not structure_files:
        print("âŒ êµ¬ì¡° JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    structure_file = structure_files[0]
    print(f"âœ“ êµ¬ì¡° íŒŒì¼: {structure_file.name}")
    
    # êµ¬ì¡° ì •ë³´ ë¡œë“œ ë° ì¶œë ¥
    with open(structure_file, 'r', encoding='utf-8', errors='replace') as f:
        structure_data = json.load(f)
    
    doc_structure = structure_data.get('document_structure', {})
    print(f"\nğŸ“Š êµ¬ì¡° ì •ë³´:")
    print(f"  - ì´ ì¥(ç« ): {doc_structure.get('total_chapters', 0)}ê°œ")
    print(f"  - ì´ ì¡°(æ¢): {doc_structure.get('total_articles', 0)}ê°œ")
    
    chapters = doc_structure.get('chapters', [])
    if chapters:
        print(f"\n  [ì¥ ëª©ë¡ (ì²˜ìŒ 5ê°œ)]:")
        for ch in chapters[:5]:
            print(f"    ì œ{ch.get('number')}ì¥: {ch.get('title')}")
            articles = ch.get('articles', [])
            if articles:
                print(f"      â””â”€ í¬í•¨ëœ ì¡°(æ¢): {len(articles)}ê°œ")
                for art in articles[:2]:
                    print(f"         ì œ{art.get('number')}ì¡°: {art.get('title', '(ì œëª© ì—†ìŒ)')}")
                if len(articles) > 2:
                    print(f"         ... ì™¸ {len(articles) - 2}ê°œ")
    
    return True


def test_2_chunk_metadata():
    """í…ŒìŠ¤íŠ¸ 2: ì²­í¬ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í™•ì¸"""
    print("\n" + "="*70)
    print("í…ŒìŠ¤íŠ¸ 2: ì²­í¬ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (chunker.py)")
    print("="*70)
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
    test_text = """ì œ1ì¥ ì´ì¹™

ì œ1ì¡° (ëª©ì ) 
ì´ ê·œì •ì€ íšŒì‚¬ì˜ ì¸ì‚¬ê´€ë¦¬ì— í•„ìš”í•œ ì‚¬í•­ì„ ê·œì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.

ì œ2ì¡° (ì ìš©ë²”ìœ„)
â‘  ì´ ê·œì •ì€ íšŒì‚¬ì˜ ëª¨ë“  ì„ì§ì›ì—ê²Œ ì ìš©í•œë‹¤.
â‘¡ ê³„ì•½ì§ ì§ì›ì€ ë³„ë„ë¡œ ì •í•œë‹¤.

ì œ3ì¥ ê¸‰ì—¬ì˜ ì§€ê¸‰

ì œ15ì¡° (ê¸‰ì—¬ì˜ ê³„ì‚°)
â‘  ê¸‰ì—¬ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•œë‹¤.
â‘¡ 1ë…„ ë¯¸ë§Œ: ì›”ê¸‰ì—¬, 1ë…„ ì´ìƒ: ì—°ê°„ 15ì¼

ì œ16ì¡° (ìƒì—¬ê¸ˆ)
ìƒì—¬ê¸ˆì€ ì—° 2íšŒ ì§€ê¸‰í•œë‹¤.

ì œ5ì¥ íœ´ê°€ ë° íœ´ì§

ì œ27ì¡° (ì—°ì°¨ íœ´ê°€)
â‘  ì—°ì°¨íœ´ê°€ëŠ” ê·¼ë¬´ê¸°ê°„ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì§€ê¸‰í•œë‹¤.
â‘¡ 1ë…„ ë¯¸ë§Œ: ì›” 1ì¼, 1ë…„ ì´ìƒ: ì—° 15ì¼"""
    
    # ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
    doc_metadata = {
        'doc_id': 'doc_test_ì¸ì‚¬ê·œì •',
        'doc_name': 'ì¸ì‚¬ê·œì • í…ŒìŠ¤íŠ¸',
        'user_id': 'user_001',
        'dept_id': 'HR',
        'project_id': 'proj_2024_001'
    }
    
    # ì²­í‚¹
    chunker = DocumentChunker(chunk_size=300, chunk_overlap=50)
    chunks = chunker.chunk_text(test_text, doc_metadata)
    
    print(f"\nâœ“ ì²­í‚¹ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬")
    
    # ê° ì²­í¬ì˜ ë©”íƒ€ë°ì´í„° í™•ì¸
    print(f"\nğŸ“‹ ì²­í¬ë³„ ë©”íƒ€ë°ì´í„°:")
    for i, chunk in enumerate(chunks):
        metadata = chunk.metadata
        print(f"\n  [ì²­í¬ {i}]")
        print(f"    - í¬ê¸°: {metadata.get('chunk_size')} ê¸€ì")
        print(f"    - ì¥(Chapter): {metadata.get('chapter_number')} - {metadata.get('chapter_title')}")
        print(f"    - ì¡°(Article): {metadata.get('article_number')} - {metadata.get('article_title')}")
        print(f"    - ê³„ì¸µ ê²½ë¡œ: {metadata.get('hierarchy_path')}")
        print(f"    - ë¶€ì„œ: {metadata.get('dept_id')}")
        print(f"    - í”„ë¡œì íŠ¸: {metadata.get('project_id')}")
        print(f"    - ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {chunk.page_content[:50]}...")
    
    return True


def test_3_pipeline_metadata():
    """í…ŒìŠ¤íŠ¸ 3: Pipelineì˜ ë©”íƒ€ë°ì´í„° ì„¤ì • í™•ì¸"""
    print("\n" + "="*70)
    print("í…ŒìŠ¤íŠ¸ 3: Pipeline ë©”íƒ€ë°ì´í„° (pipeline.py)")
    print("="*70)
    
    extracted_dir = Path(config.EXTRACTED_DIR)
    
    if not extracted_dir.exists():
        print("âŒ extracted_results í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # ì¶”ì¶œëœ í´ë” ëª©ë¡
    extracted_folders = [d for d in extracted_dir.iterdir() if d.is_dir() and d.name.startswith('extracted_')]
    
    if not extracted_folders:
        print("âŒ ì¶”ì¶œëœ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # Pipeline ì´ˆê¸°í™” (ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ, ìƒˆë¡œ ì¶”ê°€í•˜ì§€ ì•ŠìŒ)
    print("Pipeline ì´ˆê¸°í™” ì¤‘...")
    try:
        pipeline = RAGPipeline(load_existing=True)
    except Exception as e:
        print(f"âŒ Pipeline ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False
    
    # í˜„ì¬ ì €ì¥ëœ ë¬¸ì„œ ì •ë³´ í™•ì¸
    stats = pipeline.vector_store.get_collection_info()
    
    print(f"\nâœ“ ChromaDB ì»¬ë ‰ì…˜ ì •ë³´:")
    print(f"  - ì´ ë¬¸ì„œ ìˆ˜: {stats.get('count', 0)}ê°œ")
    print(f"  - ë©”íƒ€ë°ì´í„° ìƒ˜í”Œ í™•ì¸ ê°€ëŠ¥")
    
    return True


def test_4_chromadb_filtering():
    """í…ŒìŠ¤íŠ¸ 4: ChromaDB í•„í„°ë§ ë™ì‘ í™•ì¸"""
    print("\n" + "="*70)
    print("í…ŒìŠ¤íŠ¸ 4: ChromaDB í•„í„°ë§ (where ì¡°ê±´)")
    print("="*70)
    
    try:
        pipeline = RAGPipeline(load_existing=True)
    except Exception as e:
        print(f"âŒ Pipeline ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False
    
    # í˜„ì¬ ì €ì¥ëœ ë¬¸ì„œ ìˆ˜
    stats = pipeline.vector_store.get_collection_info()
    doc_count = stats.get('count', 0)
    
    if doc_count == 0:
        print("âš ï¸  ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € python auto_add.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return False
    
    print(f"âœ“ ì €ì¥ëœ ì²­í¬: {doc_count}ê°œ")
    
    # í•„í„°ë§ ì˜ˆì‹œ
    print(f"\nğŸ” í•„í„°ë§ í…ŒìŠ¤íŠ¸:")
    
    # 1. íŠ¹ì • ë¶€ì„œ í•„í„°ë§
    filter_1 = {"dept_id": "HR"}
    print(f"\n  [í•„í„° 1] ë¶€ì„œ = 'HR'")
    print(f"    í•„í„° êµ¬ì¡°: {filter_1}")
    
    # 2. íŠ¹ì • ì¥ í•„í„°ë§
    filter_2 = {"chapter_number": "3"}
    print(f"\n  [í•„í„° 2] ì¥ = '3'")
    print(f"    í•„í„° êµ¬ì¡°: {filter_2}")
    
    # 3. ë³µí•© í•„í„°
    filter_3 = {"$and": [{"dept_id": "HR"}, {"chapter_number": "3"}]}
    print(f"\n  [í•„í„° 3] ë¶€ì„œ = 'HR' AND ì¥ = '3'")
    print(f"    í•„í„° êµ¬ì¡°: {filter_3}")
    
    print(f"\nğŸ’¡ í•„í„°ë§ì„ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ë ¤ë©´:")
    print(f"   rag.query(question, where_filter=filter_1)")
    
    return True


def test_5_manual_metadata_input():
    """í…ŒìŠ¤íŠ¸ 5: ì‚¬ìš©ì ì…ë ¥ ë©”íƒ€ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜"""
    print("\n" + "="*70)
    print("í…ŒìŠ¤íŠ¸ 5: ì‚¬ìš©ì ì…ë ¥ ë©”íƒ€ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ (í”„ë¡ íŠ¸ì—”ë“œ ì…ë ¥ ëª¨ì˜)")
    print("="*70)
    
    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì…ë ¥ë°›ì„ ë©”íƒ€ë°ì´í„°
    user_input_metadata = {
        "user_id": "user_123",
        "dept_id": "HR",
        "project_id": "proj_2024_001",
        "category": "ì¸ì‚¬",
        "version": "2024ë…„ 10ì›” ê°œì •",
        "upload_date": datetime.now().isoformat()
    }
    
    print(f"\nğŸ“ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì…ë ¥ë°›ì€ ë©”íƒ€ë°ì´í„°:")
    for key, value in user_input_metadata.items():
        print(f"  - {key}: {value}")
    
    # ìë™ ìƒì„±ë˜ëŠ” ë©”íƒ€ë°ì´í„°
    auto_metadata = {
        "doc_id": "doc_ì¸ì‚¬ê·œì •_2024",
        "doc_name": "ì¸ì‚¬ê·œì •",
        "source": "extracted_results/extracted_ì¸ì‚¬ê·œì •",
        "file_type": "HWPX",
        "total_chapters": 8,
        "total_articles": 47
    }
    
    print(f"\nğŸ”„ ìë™ ì¶”ì¶œ/ìƒì„± ë©”íƒ€ë°ì´í„°:")
    for key, value in auto_metadata.items():
        print(f"  - {key}: {value}")
    
    # ë³‘í•©ëœ ë©”íƒ€ë°ì´í„°
    merged_metadata = {**auto_metadata, **user_input_metadata}
    
    print(f"\nâœ… ìµœì¢… ë³‘í•© ë©”íƒ€ë°ì´í„°:")
    for key, value in merged_metadata.items():
        print(f"  - {key}: {value}")
    
    print(f"\nğŸ’¾ ì´ ë©”íƒ€ë°ì´í„°ê°€ ê° ì²­í¬ì— ì €ì¥ë˜ì–´:")
    print(f"   - ChromaDBì— ì €ì¥ë¨")
    print(f"   - ê²€ìƒ‰ í•„í„°ë§ ì‹œ ì‚¬ìš©ë¨")
    print(f"   - RAG ë‹µë³€ì˜ ì¶œì²˜ ì •ë³´ë¡œ í™œìš©ë¨")
    
    return True


def test_6_config_schema():
    """í…ŒìŠ¤íŠ¸ 6: config.pyì˜ ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ í™•ì¸"""
    print("\n" + "="*70)
    print("í…ŒìŠ¤íŠ¸ 6: ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜ (config.py)")
    print("="*70)
    
    print(f"\nğŸ“‹ ë¬¸ì„œ ë ˆë²¨ ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ:")
    print(f"  {json.dumps(config.DOCUMENT_METADATA_SCHEMA, ensure_ascii=False, indent=2)}")
    
    print(f"\nğŸ“‹ í•„í„°ë§ ì˜ˆì‹œ:")
    for filter_name, filter_value in config.METADATA_FILTER_EXAMPLES.items():
        print(f"\n  {filter_name}:")
        print(f"    {filter_value}")
    
    return True


def main():
    """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "ğŸ§ª ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ë™ì‘ í…ŒìŠ¤íŠ¸ ì‹œì‘" + "\n")
    
    tests = [
        ("êµ¬ì¡° ì •ë³´ ì¶”ì¶œ", test_1_structure_extraction),
        ("ì²­í¬ ë©”íƒ€ë°ì´í„°", test_2_chunk_metadata),
        ("Pipeline ë©”íƒ€ë°ì´í„°", test_3_pipeline_metadata),
        ("ChromaDB í•„í„°ë§", test_4_chromadb_filtering),
        ("ì‚¬ìš©ì ì…ë ¥ ì‹œë®¬ë ˆì´ì…˜", test_5_manual_metadata_input),
        ("ìŠ¤í‚¤ë§ˆ ì •ì˜", test_6_config_schema)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results[test_name] = "âœ… ì„±ê³µ" if result else "âš ï¸  í™•ì¸ í•„ìš”"
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            results[test_name] = f"âŒ ì‹¤íŒ¨: {str(e)}"
    
    # ìµœì¢… ê²°ê³¼ ìš”ì•½
    print("\n" + "="*70)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*70)
    
    for test_name, result in results.items():
        print(f"{result} - {test_name}")
    
    print("\n" + "="*70)
    print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("="*70)
    print("""
1. í”„ë¡ íŠ¸ì—”ë“œ/ë°±ì—”ë“œ ì—°ë™ ì—†ì´ ë©”íƒ€ë°ì´í„° ë™ì‘ í™•ì¸ ì™„ë£Œ
2. ì‹¤ì œ ë¬¸ì„œë¡œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´:
   - python extract.py "ë¬¸ì„œ ê²½ë¡œ" (ë¬¸ì„œ íŒŒì‹±)
   - python auto_add.py (RAG ì‹œìŠ¤í…œì— ì¶”ê°€)
3. ê²€ìƒ‰ í•„í„°ë§ í…ŒìŠ¤íŠ¸:
   - test_search_with_filters.py ì‹¤í–‰
4. ë°±ì—”ë“œ ê°œë°œìì—ê²Œ ì „ë‹¬:
   - ë©”íƒ€ë°ì´í„°_ìŠ¤í‚¤ë§ˆ_ê°€ì´ë“œ.md ê³µìœ 
   - í•„ìš”í•œ API êµ¬ì¡° í˜‘ì˜
    """)


if __name__ == "__main__":
    main()

