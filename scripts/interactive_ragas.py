"""
ëŒ€í™”í˜• RAGAS í‰ê°€
ì‚¬ìš©ìê°€ ì§ì ‘ ì§ˆë¬¸í•˜ê³  ë‹µë³€ì— ëŒ€í•´ ì¦‰ì‹œ í‰ê°€
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from rag.pipeline import RAGPipeline
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy
from datasets import Dataset
import time

def interactive_ragas_evaluation():
    """ëŒ€í™”í˜• RAGAS í‰ê°€"""
    
    print("="*70)
    print("ëŒ€í™”í˜• RAGAS í‰ê°€")
    print("="*70)
    print("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ RAG ì‹œìŠ¤í…œì´ ë‹µë³€í•˜ê³ , RAGASë¡œ í‰ê°€í•©ë‹ˆë‹¤.")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")
    
    # RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    print("RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")
    pipeline = RAGPipeline(load_existing=True)
    print("âœ… ì¤€ë¹„ ì™„ë£Œ\n")
    
    # í‰ê°€ ë°ì´í„° ìˆ˜ì§‘
    questions = []
    answers = []
    contexts_list = []
    ground_truths = []
    response_times = []
    
    while True:
        print("-"*70)
        question = input("\nì§ˆë¬¸: ").strip()
        
        if question.lower() in ['quit', 'exit', 'q']:
            break
        
        if not question:
            print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue
        
        # ì •ë‹µ(Ground Truth) ì…ë ¥
        print("\n[ì •ë‹µ ì…ë ¥]")
        print("(í‰ê°€ë¥¼ ìœ„í•´ ê¸°ëŒ€í•˜ëŠ” ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”. ëª¨ë¥´ë©´ Enter)")
        ground_truth = input("ì •ë‹µ: ").strip()
        
        if not ground_truth:
            ground_truth = "ì •ë‹µ ë¯¸ì œê³µ"
        
        # RAG ì§ˆì˜ ì‹¤í–‰
        print("\në‹µë³€ ìƒì„± ì¤‘...")
        start_time = time.time()
        result = pipeline.query(question, top_k=5)
        elapsed = time.time() - start_time
        
        answer = result.get("answer", "")
        sources = result.get("sources", [])
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*70)
        print("ğŸ“ ë‹µë³€:")
        print("="*70)
        print(answer)
        print(f"\nâ±ï¸ ì‘ë‹µ ì‹œê°„: {elapsed:.2f}ì´ˆ")
        
        print(f"\nğŸ“š ì¶œì²˜: ({len(sources)}ê°œ)")
        for i, src in enumerate(sources[:3], 1):
            doc_name = src['metadata'].get('doc_name', 'N/A')
            hierarchy = src['metadata'].get('hierarchy_path', '')
            print(f"  [{i}] {doc_name}")
            if hierarchy:
                print(f"      ìœ„ì¹˜: {hierarchy}")
            print(f"      ë‚´ìš©: {src['content'][:100]}...")
        
        # í‰ê°€ ë°ì´í„° ì €ì¥
        questions.append(question)
        answers.append(answer)
        ground_truths.append([ground_truth])
        response_times.append(elapsed)
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤
        contexts = [src['content'] for src in sources if src.get('content')]
        contexts_list.append(contexts if contexts else ["ì •ë³´ ì—†ìŒ"])
        
        # ê³„ì† ì—¬ë¶€ í™•ì¸
        print("\n" + "-"*70)
        continue_choice = input("\në‹¤ë¥¸ ì§ˆë¬¸ì„ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if continue_choice == 'n':
            break
    
    # í‰ê°€ ì‹¤í–‰
    if not questions:
        print("\ní‰ê°€í•  ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("\n\n" + "="*70)
    print("RAGAS í‰ê°€ ì‹œì‘")
    print("="*70)
    print(f"ì´ {len(questions)}ê°œ ì§ˆë¬¸ í‰ê°€ ì¤‘...\n")
    
    # Dataset ìƒì„±
    data = {
        "question": questions,
        "contexts": contexts_list,
        "answer": answers,
        "ground_truths": ground_truths
    }
    dataset = Dataset.from_dict(data)
    
    # RAGAS í‰ê°€
    try:
        result = evaluate(
            dataset,
            metrics=[faithfulness, answer_relevancy]
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*70)
        print("RAGAS í‰ê°€ ê²°ê³¼")
        print("="*70)
        
        print(f"\nì´ ì§ˆë¬¸: {len(questions)}ê°œ")
        
        # ì‘ë‹µ ì‹œê°„ í†µê³„
        avg_time = sum(response_times) / len(response_times)
        print(f"\nì‘ë‹µ ì†ë„:")
        print(f"  í‰ê· : {avg_time:.2f}ì´ˆ")
        print(f"  ìµœì†Œ: {min(response_times):.2f}ì´ˆ")
        print(f"  ìµœëŒ€: {max(response_times):.2f}ì´ˆ")
        
        # RAGAS ì§€í‘œ
        print(f"\nRAGAS ì§€í‘œ:")
        print(f"  Faithfulness (ì‹ ë¢°ì„±):     {result['faithfulness']:.3f}")
        print(f"  Answer Relevancy (ê´€ë ¨ì„±): {result['answer_relevancy']:.3f}")
        
        # í‰ê· 
        avg_score = (result['faithfulness'] + result['answer_relevancy']) / 2
        print(f"  í‰ê·  ì ìˆ˜:                  {avg_score:.3f}")
        
        # íŒì •
        print("\níŒì •:")
        if avg_score >= 0.85:
            print("  âœ… ìš°ìˆ˜ - í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ")
        elif avg_score >= 0.70:
            print("  âš ï¸ ë³´í†µ - ê°œì„  ê¶Œì¥")
        else:
            print("  âŒ ê°œì„  í•„ìš” - ì‹œìŠ¤í…œ ì ê²€ í•„ìš”")
        
        # ì§ˆë¬¸ë³„ ìƒì„¸ ê²°ê³¼
        print("\n" + "="*70)
        print("ì§ˆë¬¸ë³„ ìƒì„¸ ê²°ê³¼")
        print("="*70)
        for i, (q, a) in enumerate(zip(questions, answers), 1):
            print(f"\n[{i}] {q}")
            print(f"    ë‹µë³€: {a[:100]}...")
            print(f"    ì‘ë‹µ ì‹œê°„: {response_times[i-1]:.2f}ì´ˆ")
        
        print("\n" + "="*70)
        
    except Exception as e:
        print(f"\nâŒ RAGAS í‰ê°€ ì‹¤íŒ¨: {e}")
        print("\nì…ë ¥í•œ ì§ˆë¬¸ê³¼ ë‹µë³€:")
        for i, (q, a) in enumerate(zip(questions, answers), 1):
            print(f"\n[{i}] Q: {q}")
            print(f"    A: {a[:150]}...")


if __name__ == "__main__":
    interactive_ragas_evaluation()


