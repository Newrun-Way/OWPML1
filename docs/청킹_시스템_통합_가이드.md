# ì²­í‚¹ ì‹œìŠ¤í…œ í†µí•© ê°€ì´ë“œ

> ë°±ì—”ë“œ ê°œë°œìë¥¼ ìœ„í•œ ì‹¤ì „ ê°€ì´ë“œ

## 1. ë¹ ë¥¸ ì´í•´: ë‘ ê°€ì§€ ì²­í‚¹ ë°©ì‹

### ğŸ“Š ë¹„êµí‘œ

| í•­ëª© | DocumentChunker | StructureAwareChunker |
|------|-----------------|----------------------|
| **ì–¸ì œ ì‚¬ìš©?** | ì¼ë°˜ ë¬¸ì„œ (ë³´ê³ ì„œ, ë©”ëª¨ ë“±) | ë²•ë ¹/ê·œì • ë“± êµ¬ì¡°í™”ëœ ë¬¸ì„œ |
| **ì²­í‚¹ ë°©ì‹** | í…ìŠ¤íŠ¸ ë¶„í•  â†’ êµ¬ì¡° ì—­ì¶”ì  | êµ¬ì¡° íŒŒì‹± â†’ ì˜ë¯¸ë‹¨ìœ„ ë¶„í•  |
| **ì¥ì ** | ë¹ ë¦„, ë‹¨ìˆœí•¨ | ì˜ë¯¸ ë‹¨ìœ„ ë³´ì¡´, ê²€ìƒ‰ ì •í™•ë„ â†‘ |
| **ë‹¨ì ** | ì˜ë¯¸ ë‹¨ìœ„ ê¹¨ì§ˆ ìˆ˜ ìˆìŒ | ì•½ê°„ ëŠë¦¼ |

### ğŸ¯ ì„ íƒ ê¸°ì¤€

```python
# Case 1: ë²•ë ¹, ê·œì •, ê³„ì•½ì„œ ë“± "ì œXXì¡°" í˜•ì‹ì´ ìˆëŠ” ë¬¸ì„œ
use_structure_chunking = True

# Case 2: ì¼ë°˜ ë³´ê³ ì„œ, ë©”ëª¨, ììœ  í˜•ì‹ ë¬¸ì„œ
use_structure_chunking = False

# Case 3: í˜¼ì¬ëœ ê²½ìš° (ê¶Œì¥)
use_structure_chunking = True  # StructureAwareChunkerê°€ ìë™ìœ¼ë¡œ fallback ì²˜ë¦¬
```

---

## 2. API í†µí•© ë°©ë²•

### 2.1 ê¸°ë³¸ ì‚¬ìš©ë²•

**íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”**

```python
from rag.pipeline import RAGPipeline

# êµ¬ì¡° ìš°ì„  ì²­í‚¹ ì‚¬ìš© (ê¸°ë³¸ê°’, ê¶Œì¥)
pipeline = RAGPipeline(
    load_existing=True,
    use_structure_chunking=True  # ì´ í”Œë˜ê·¸ê°€ í•µì‹¬
)

# ì¼ë°˜ ì²­í‚¹ ì‚¬ìš©
pipeline = RAGPipeline(
    load_existing=True,
    use_structure_chunking=False
)
```

### 2.2 FastAPI ì—”ë“œí¬ì¸íŠ¸ ì˜ˆì‹œ

**ë¬¸ì„œ ì—…ë¡œë“œ ì‹œ ì²­í‚¹ ë°©ì‹ ì„ íƒ**

```python
from fastapi import APIRouter, UploadFile
from pydantic import BaseModel

router = APIRouter()

class DocumentUploadRequest(BaseModel):
    use_structure_chunking: bool = True  # ê¸°ë³¸ê°’: êµ¬ì¡° ìš°ì„  ì²­í‚¹

@router.post("/api/documents/upload")
async def upload_document(
    file: UploadFile,
    use_structure_chunking: bool = True
):
    """
    ë¬¸ì„œ ì—…ë¡œë“œ ë° ì²­í‚¹
    
    Args:
        file: HWP/HWPX íŒŒì¼
        use_structure_chunking: True=êµ¬ì¡° ìš°ì„ , False=ì¼ë°˜ ì²­í‚¹
    """
    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    pipeline = RAGPipeline(
        load_existing=True,
        use_structure_chunking=use_structure_chunking
    )
    
    # ë¬¸ì„œ ì²˜ë¦¬
    result = pipeline.add_document_from_extract(extracted_dir)
    
    return {
        "status": "success",
        "chunking_method": "structure-aware" if use_structure_chunking else "general",
        "chunks_created": result["chunk_count"]
    }
```

**ê²€ìƒ‰ ì‹œ ì²­í‚¹ ë©”íƒ€ë°ì´í„° í™œìš©**

```python
@router.post("/api/query")
async def query(request: QueryRequest):
    """
    ì§ˆì˜ì‘ë‹µ
    """
    results = pipeline.query(
        query=request.query,
        top_k=10
    )
    
    # ì‘ë‹µì— ì²­í‚¹ ì •ë³´ í¬í•¨
    sources = []
    for doc in results["sources"]:
        sources.append({
            "content": doc["content"],
            "doc_name": doc["doc_name"],
            "hierarchy_path": doc.get("hierarchy_path", ""),  # êµ¬ì¡° ê²½ë¡œ
            "chapter": doc.get("chapter_title", ""),
            "article": doc.get("article_title", ""),
            "chunking_strategy": doc.get("chunking_strategy", "general")  # ì²­í‚¹ ë°©ì‹
        })
    
    return {
        "answer": results["answer"],
        "sources": sources
    }
```

---

## 3. ì²­í‚¹ ì „ëµë³„ ìƒì„¸ ë™ì‘

### 3.1 StructureAwareChunker (êµ¬ì¡° ìš°ì„ )

**ë™ì‘ ìˆœì„œ**

```
1. ë¬¸ì„œ êµ¬ì¡° íŒŒì‹±
   â†“
2. "ì œXXì¡°" ë‹¨ìœ„ë¡œ ë¶„í• 
   â†“
3. í¬ê¸° ì²´í¬
   - ë„ˆë¬´ í¬ë©´ â†’ í•­(â‘ â‘¡â‘¢) ë‹¨ìœ„ë¡œ ì¬ë¶„í• 
   - ë„ˆë¬´ ì‘ìœ¼ë©´ â†’ ë‹¤ìŒ ì¡°ì™€ ë³‘í•©
   - ì ë‹¹í•˜ë©´ â†’ ê·¸ëŒ€ë¡œ ì²­í¬ ìƒì„±
   â†“
4. êµ¬ì¡° ì—†ìœ¼ë©´ â†’ ìë™ìœ¼ë¡œ ì¼ë°˜ ì²­í‚¹ (fallback)
```

**ì½”ë“œ ì˜ˆì‹œ**

```python
from rag.structure_chunker import StructureAwareChunker

chunker = StructureAwareChunker(
    max_chunk_size=800,   # ìµœëŒ€ ì²­í¬ í¬ê¸°
    min_chunk_size=200,   # ìµœì†Œ ì²­í¬ í¬ê¸°
    overlap_size=150      # ì²­í¬ ê°„ ê²¹ì¹¨
)

# ì²­í‚¹ ì‹¤í–‰
chunks = chunker.chunk_by_structure(
    text=document_text,
    metadata={"doc_name": "ì¸ì‚¬ê·œì •", "user_id": "user123"}
)

# ê²°ê³¼ í™•ì¸
for chunk in chunks:
    print(f"í¬ê¸°: {len(chunk.page_content)}")
    print(f"ê²½ë¡œ: {chunk.metadata['hierarchy_path']}")
    print(f"ì „ëµ: {chunk.metadata.get('chunking_strategy', 'structure')}")
```

**ìƒì„±ë˜ëŠ” ë©”íƒ€ë°ì´í„°**

```python
{
    "doc_name": "ì¸ì‚¬ê·œì •",
    "chunk_index": 0,
    "chunk_size": 456,
    "chapter_number": "3",
    "chapter_title": "ê¸‰ì—¬ ë° ìˆ˜ë‹¹",
    "article_number": "15",
    "article_title": "ê¸‰ì—¬ì˜ ê³„ì‚°",
    "hierarchy_path": "ì œ3ì¥ ê¸‰ì—¬ ë° ìˆ˜ë‹¹ > ì œ15ì¡° (ê¸‰ì—¬ì˜ ê³„ì‚°)",
    "chunking_strategy": "structure"  # or "general" (fallback ì‹œ)
}
```

### 3.2 DocumentChunker (ì¼ë°˜ ì²­í‚¹)

**ë™ì‘ ìˆœì„œ**

```
1. í…ìŠ¤íŠ¸ë¥¼ ì¼ì • í¬ê¸°ë¡œ ë¶„í•  (RecursiveCharacterTextSplitter)
   â†“
2. ê° ì²­í¬ì˜ ìœ„ì¹˜ë¥¼ ì—­ì¶”ì í•˜ì—¬ êµ¬ì¡° ì •ë³´ ì¶”ê°€
   â†“
3. ë©”íƒ€ë°ì´í„° ìƒì„±
```

**ì½”ë“œ ì˜ˆì‹œ**

```python
from rag.chunker import DocumentChunker

chunker = DocumentChunker(
    chunk_size=800,
    chunk_overlap=150
)

# ì²­í‚¹ ì‹¤í–‰
chunks = chunker.chunk_text(
    text=document_text,
    metadata={"doc_name": "íšŒì˜ë¡", "user_id": "user123"}
)
```

---

## 4. ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ë²•ë ¹ ë¬¸ì„œ ì²˜ë¦¬

```python
# ì¶”ì²œ: StructureAwareChunker (ìë™ ì ìš©)
pipeline = RAGPipeline(use_structure_chunking=True)

# ì²˜ë¦¬ ê²°ê³¼
# âœ… ì œ15ì¡° ì „ì²´ê°€ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ìœ ì§€
# âœ… hierarchy_pathë¡œ ì •í™•í•œ ìœ„ì¹˜ ì¶”ì 
# âœ… ê²€ìƒ‰ ì‹œ ì¡° ë‹¨ìœ„ë¡œ ì •í™•í•œ ë‹µë³€
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ì¼ë°˜ ë³´ê³ ì„œ ì²˜ë¦¬

```python
# ë°©ë²• 1: StructureAwareChunker ì‚¬ìš© (ê¶Œì¥)
pipeline = RAGPipeline(use_structure_chunking=True)
# â†’ êµ¬ì¡°ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì¼ë°˜ ì²­í‚¹ ì ìš© (fallback)

# ë°©ë²• 2: DocumentChunker ì§ì ‘ ì‚¬ìš©
pipeline = RAGPipeline(use_structure_chunking=False)
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: í˜¼ì¬ëœ ë¬¸ì„œ ì²˜ë¦¬

```python
# StructureAwareChunker ì‚¬ìš© (ê¶Œì¥)
pipeline = RAGPipeline(use_structure_chunking=True)

# ê²°ê³¼:
# - ë²•ë ¹ ë¬¸ì„œ â†’ êµ¬ì¡° ê¸°ë°˜ ì²­í‚¹
# - ì¼ë°˜ ë¬¸ì„œ â†’ ìë™ fallbackìœ¼ë¡œ ì¼ë°˜ ì²­í‚¹
# - ëª¨ë“  ë¬¸ì„œê°€ ì ì ˆí•˜ê²Œ ì²˜ë¦¬ë¨
```

---

## 5. ì„±ëŠ¥ ìµœì í™” íŒ

### 5.1 ì²­í¬ í¬ê¸° ì¡°ì •

```python
# ê²€ìƒ‰ ì •í™•ë„ ìš°ì„ 
chunker = StructureAwareChunker(
    max_chunk_size=600,   # ì‘ê²Œ
    min_chunk_size=150
)

# ì²˜ë¦¬ ì†ë„ ìš°ì„ 
chunker = StructureAwareChunker(
    max_chunk_size=1200,  # í¬ê²Œ
    min_chunk_size=300
)

# ê· í˜•ì¡íŒ ì„¤ì • (ê¸°ë³¸ê°’)
chunker = StructureAwareChunker(
    max_chunk_size=800,
    min_chunk_size=200
)
```

### 5.2 ë°°ì¹˜ ì²˜ë¦¬

```python
from pathlib import Path

def batch_process_documents(extracted_dirs: List[Path]):
    """
    ì—¬ëŸ¬ ë¬¸ì„œ ì¼ê´„ ì²˜ë¦¬
    """
    pipeline = RAGPipeline(use_structure_chunking=True)
    
    results = []
    for extracted_dir in extracted_dirs:
        try:
            result = pipeline.add_document_from_extract(extracted_dir)
            results.append({
                "doc_name": extracted_dir.name,
                "status": "success",
                "chunks": result["chunk_count"]
            })
        except Exception as e:
            results.append({
                "doc_name": extracted_dir.name,
                "status": "failed",
                "error": str(e)
            })
    
    return results
```

---

## 6. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: ì²­í¬ê°€ ë„ˆë¬´ ë§ì´ ìƒì„±ë¨

**ì›ì¸**: `max_chunk_size`ê°€ ë„ˆë¬´ ì‘ìŒ

**í•´ê²°**:
```python
chunker = StructureAwareChunker(
    max_chunk_size=1200,  # ê¸°ë³¸ 800 â†’ 1200ìœ¼ë¡œ ì¦ê°€
    min_chunk_size=300
)
```

### ë¬¸ì œ 2: ì¡° ë‹¨ìœ„ê°€ ê¹¨ì§

**ì›ì¸**: `use_structure_chunking=False` ì‚¬ìš© ì¤‘

**í•´ê²°**:
```python
# False â†’ Trueë¡œ ë³€ê²½
pipeline = RAGPipeline(use_structure_chunking=True)
```

### ë¬¸ì œ 3: ì¼ë°˜ ë¬¸ì„œê°€ ì²­í‚¹ë˜ì§€ ì•ŠìŒ

**ì›ì¸**: ì—†ìŒ (ìë™ fallbackì´ ë™ì‘í•¨)

**í™•ì¸**:
```python
# ë©”íƒ€ë°ì´í„° í™•ì¸
for chunk in chunks:
    strategy = chunk.metadata.get('chunking_strategy', 'unknown')
    print(f"ì²­í‚¹ ì „ëµ: {strategy}")  # 'general' ë˜ëŠ” 'structure'
```

### ë¬¸ì œ 4: ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì›ì¸**: ë„ˆë¬´ ë§ì€ ë¬¸ì„œë¥¼ í•œë²ˆì— ì²˜ë¦¬

**í•´ê²°**:
```python
# ë°°ì¹˜ í¬ê¸° ì œí•œ
BATCH_SIZE = 10

for i in range(0, len(doc_list), BATCH_SIZE):
    batch = doc_list[i:i+BATCH_SIZE]
    batch_process_documents(batch)
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    import gc
    gc.collect()
```

---

## 7. ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê°œë°œ ì „

- [ ] ë¬¸ì„œ ìœ í˜• í™•ì¸ (ë²•ë ¹ vs ì¼ë°˜)
- [ ] ì²­í‚¹ ì „ëµ ì„ íƒ (`use_structure_chunking` í”Œë˜ê·¸)
- [ ] ì²­í¬ í¬ê¸° ì„¤ì • ê²°ì •

### ê°œë°œ ì¤‘

- [ ] íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œ í”Œë˜ê·¸ ì „ë‹¬
- [ ] API ì—”ë“œí¬ì¸íŠ¸ì— ì²­í‚¹ ë°©ì‹ íŒŒë¼ë¯¸í„° ì¶”ê°€
- [ ] ë©”íƒ€ë°ì´í„°ì— `chunking_strategy` í¬í•¨

### ê°œë°œ í›„

- [ ] í…ŒìŠ¤íŠ¸ ë¬¸ì„œë¡œ ì²­í‚¹ ê²°ê³¼ í™•ì¸
- [ ] `hierarchy_path` ë©”íƒ€ë°ì´í„° í™•ì¸
- [ ] ê²€ìƒ‰ ì •í™•ë„ ê²€ì¦
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

---

## 8. ì°¸ê³  ìë£Œ

- **ìƒì„¸ ì˜ˆì‹œ**: `docs/ì¥ì¡°í•­í˜¸_êµ¬ì¡°_ì²­í‚¹_ìƒì„¸_ì˜ˆì‹œ.md`
- **ì‹œê°í™” ìë£Œ**: `docs/ì‹¤ì œ_ë¬¸ì„œ_ìƒ‰ì¸_êµ¬ì¡°_ì‹œê°í™”.md`
- **í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ**: `docs/íŒŒì´í”„ë¼ì¸_í…ŒìŠ¤íŠ¸_ê°€ì´ë“œ.md`
- **ì†ŒìŠ¤ ì½”ë“œ**:
  - `rag/structure_chunker.py` - êµ¬ì¡° ìš°ì„  ì²­í‚¹
  - `rag/chunker.py` - ì¼ë°˜ ì²­í‚¹
  - `rag/pipeline.py` - í†µí•© íŒŒì´í”„ë¼ì¸

---

## 9. ë¹ ë¥¸ ì°¸ì¡°

### ìµœì†Œ ì½”ë“œë¡œ ì‹œì‘í•˜ê¸°

```python
# 1. íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
from rag.pipeline import RAGPipeline
pipeline = RAGPipeline(use_structure_chunking=True)

# 2. ë¬¸ì„œ ì¶”ê°€
pipeline.add_document_from_extract(extracted_dir)

# 3. ê²€ìƒ‰
results = pipeline.query("ê¸‰ì—¬ëŠ” ì–¸ì œ ì§€ê¸‰ë˜ë‚˜ìš”?", top_k=5)

# 4. ê²°ê³¼ í™•ì¸
print(results["answer"])
for source in results["sources"]:
    print(f"- {source['hierarchy_path']}: {source['content'][:100]}")
```

### API ì‘ë‹µ ì˜ˆì‹œ

```json
{
  "answer": "ê¸‰ì—¬ëŠ” ë§¤ì›” 25ì¼ì— ì§€ê¸‰ë©ë‹ˆë‹¤...",
  "sources": [
    {
      "content": "ì œ17ì¡° (ê¸‰ì—¬ì˜ ì§€ê¸‰ì¼) â‘  ê¸‰ì—¬ëŠ” ë§¤ì›” 25ì¼ì— ì§€ê¸‰í•œë‹¤...",
      "doc_name": "ì¸ì‚¬ê·œì •",
      "hierarchy_path": "ì œ3ì¥ ê¸‰ì—¬ ë° ìˆ˜ë‹¹ > ì œ17ì¡° (ê¸‰ì—¬ì˜ ì§€ê¸‰ì¼)",
      "chapter_title": "ê¸‰ì—¬ ë° ìˆ˜ë‹¹",
      "article_title": "ê¸‰ì—¬ì˜ ì§€ê¸‰ì¼",
      "chunking_strategy": "structure"
    }
  ],
  "metadata": {
    "total_sources": 3,
    "processing_time": "1.2s"
  }
}
```

---

**ì§ˆë¬¸ì´ë‚˜ ë¬¸ì œê°€ ìˆìœ¼ë©´ íŒ€ ì±„ë„ì— ë¬¸ì˜í•˜ì„¸ìš”!** ğŸš€

